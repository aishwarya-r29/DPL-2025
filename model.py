# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dwrlRAytEcmMmSd-ffSW3CsuGxvZI2wn
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import glob
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.models import load_model

# ============================
# STEP 1: Load & Merge Data
# ============================
def load_trend_data(folder_path="/content/drive/MyDrive/Colab Notebooks/TrendDataset"):
    all_files = glob.glob(os.path.join(folder_path, "*.csv"))
    df_list = []

    for file in all_files:
        try:
            # Try utf-8 first
            df = pd.read_csv(file, encoding="utf-8", on_bad_lines="skip")
        except UnicodeDecodeError:
            # Fallback to latin1
            df = pd.read_csv(file, encoding="latin1", on_bad_lines="skip")

        # Standardize year column names (2000 [YR2000] ‚Üí 2000)
        df.rename(columns=lambda x: str(x).split()[0] if "YR" in str(x) else x, inplace=True)
        df_list.append(df)

    # Concatenate all CSVs
    merged = pd.concat(df_list, axis=0, ignore_index=True)

    # Extract only numeric year columns
    year_cols = [c for c in merged.columns if str(c).isdigit()]
    merged = merged[year_cols].transpose()  # years as rows

    merged.index = merged.index.astype(int)
    merged = merged.sort_index()  # ensure chronological order

    # Convert '..' to NaN
    merged.replace('..', np.nan, inplace=True)

    return merged

# ============================
# STEP 2: Prepare Data
# ============================
def prepare_sequences(data, look_back=5):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:i+look_back])
        y.append(data[i+look_back])
    return np.array(X), np.array(y)

# ============================
# STEP 3: Build LSTM Model
# ============================
def build_model(input_shape):
    model = Sequential([
        LSTM(64, activation='tanh', input_shape=input_shape, return_sequences=True),
        Dropout(0.2),
        LSTM(32, activation='tanh'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

# ============================
# MAIN EXECUTION
# ============================
if __name__ == "__main__":
    # Load dataset
    data = load_trend_data("/content/drive/MyDrive/Colab Notebooks/TrendDataset")
    print("Data Shape:", data.shape)

    # --- Pick one indicator for univariate forecasting ---
    series = None
    chosen_col = None
    look_back = 5  # Define look_back here

    for col in data.columns:
        candidate = data[col].dropna()
        # Ensure candidate has enough data points to create at least one sequence
        if len(candidate) >= look_back + 1:
            series = candidate
            chosen_col = col # Store the chosen column index
            break

    if series is None:
        print(f"‚ùå No column found with at least {look_back + 1} non-NaN data points after cleaning.")
    else:
        print(f"‚úÖ Using column with index: {chosen_col} and shape: {series.shape}")
        values = series.values.reshape(-1, 1)

        # Normalize
        scaler = MinMaxScaler()
        scaled = scaler.fit_transform(values)

        # Prepare sequences
        X, y = prepare_sequences(scaled, look_back=look_back)
        X = X.reshape((X.shape[0], X.shape[1], 1))  # [samples, timesteps, features]

        print("X Shape:", X.shape, "y Shape:", y.shape)

        # Build & train
        model = build_model((X.shape[1], X.shape[2]))
        model.fit(X, y, epochs=20, batch_size=16, verbose=1)

        # Save model in the native Keras format
        os.makedirs("model_files", exist_ok=True)
        model.save("model_files/Model.keras")
        print("‚úÖ LSTM Model saved at model_files/Model.keras")

from tensorflow.keras.models import load_model
import numpy as np

# Load the saved model in the native Keras format
model = load_model("model_files/Model.keras")

# Predict the next value after the last sequence
last_seq = scaled[-5:].reshape((1, 5, 1))  # last 5 timesteps
next_pred_scaled = model.predict(last_seq)

# Inverse scale back to original values
next_pred = scaler.inverse_transform(next_pred_scaled)
print("üîÆ Next predicted value:", next_pred[0][0])